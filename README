# How to reproduce our results:

1. The file `generate_personas.py` is used to generate different personas according to several categories. In order to recreate our results you need to use the "personas.csv" we had in order to avoid generating different personas.

The personas are generated/read automatically by `dataset.py`, which is responsible for generating prompts containing the persona + question + first/third person phrasing.
The questions are determinisitic and so is the phrasing format.

2. The file `main.py` uses [`dataset.py` `models.py`, `sentiment.py`] in order to download the model we use, run with the prompts generated by dataset.py, and use sentiment.py to get the sentiment report on the LLM-generated text. As a user you only need to set the `model_name` variable in `main.py` to the relevant model to test (from models.<______>_model_name), and set a HuggingFace token in 'models.py' and run the `main.py` script. The output will be a csv of the persona, questions and answers.

3. After you have the csv of the model answers on questions, you set the relevant model name in `sentiment_comparisons.py` and run it to provide graphs to visualize experiment result.

4. The last step is to run `statistics.py`